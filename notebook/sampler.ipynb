{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Pkg; Pkg.activate(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Distributions: Normal, MvNormal, Exponential, logpdf, pdf\n",
    "import Plots\n",
    "import PyPlot\n",
    "import Statistics: mean, std\n",
    "using CreditRisk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Verify slicesampler works on 1D and 2D Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = slicesample(zeros(1), x -> pdf(Normal(), x[1]), 5000; \n",
    "    step_limit=10, width=0.5, burn=20, thin=1)\n",
    "print(\"mean: $(mean(samples))  std: $(std(samples))\")\n",
    "\n",
    "PyPlot.plt[:hist](vec(samples), bins=20, density=true)\n",
    "xs = -3:0.01:3\n",
    "ys = [pdf(Normal(), x) for x in xs]\n",
    "PyPlot.plt[:plot](xs, ys, color=\"red\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = slicesample(zeros(2), pdf(MvNormal(2, 1), x), 5000; \n",
    "    step_limit=10, width=1., burn=20, thin=1)\n",
    "print(\"mean: $(mean(samples))  std: $(std(samples))\")\n",
    "PyPlot.plt[:hist2d](samples[1,:], samples[2,:], bins=20)\n",
    "\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use slice sampler on zero variance distribution π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import LinearAlgebra: mul!\n",
    "\n",
    "\" Computes μ for the approximating standard normal of loss probability\"\n",
    "function approx_μ(pnc, weights, A)\n",
    "    @. A = pnc * weights\n",
    "    sum(A)\n",
    "end\n",
    "\n",
    "\n",
    "\" Computes σ for the approximating standard normal of loss probability\"\n",
    "function approx_σ(pnc, lgc, ead, A, B, C)\n",
    "    n, c = size(lgc)\n",
    "    i = 1\n",
    "\n",
    "    lgcs = Vector{SubArray}(undef, c)\n",
    "    pncs = Vector{SubArray}(undef, c)\n",
    "    for idx = 1:c\n",
    "        lgcs[idx] = @view lgc[:,idx]\n",
    "        pncs[idx] = @view pnc[:,idx]\n",
    "    end\n",
    "\n",
    "    for a = 1:c\n",
    "        for b = 1:(a-1)\n",
    "            @. A[:,i] = (lgcs[a] - lgcs[b])^2 * pncs[a] * pncs[b]\n",
    "            i += 1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    sum!(B, A)\n",
    "    @. C = ead^2 * B\n",
    "    sqrt(sum(C) / sum(ead)^2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S=1\n",
    "\n",
    "slice sampler is not able to perform well. Because 1 mode in this bimodal distribution is always being sampled from. The other mode can be never be reached since they are quite far apart. We can improve this by doing slice sampling twice, each at a mode of a multimodal distribution. As shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 2500\n",
    "c = 4\n",
    "s = 1\n",
    "l = 1.8\n",
    "param = Parameter(n,c,s,l)\n",
    "(N, C, S, l, cmm, ead, lgc, cn, β, H, denom, weights) = unpack(param)\n",
    "\n",
    "\n",
    "Z = zeros(S)\n",
    "βZ = zeros(N)\n",
    "phi0 = zeros(N, C+1)\n",
    "phi  = @view phi0[:,2:end]\n",
    "pnc = zeros(N, C)\n",
    "approx_μ_A = similar(weights)\n",
    "approx_σ_A = zeros(N, convert(Int, (C-1)*C/2))\n",
    "approx_σ_B = zeros(N)\n",
    "approx_σ_C = zeros(N)\n",
    "Zdist = MvNormal(S, 1)\n",
    "\n",
    "function π(Z)\n",
    "    mul!(βZ, β, Z)\n",
    "    @. phi = normcdf((H - βZ) / denom)\n",
    "    diff!(pnc, phi0; dims=2)\n",
    "    μ = approx_μ(pnc, weights, approx_μ_A)\n",
    "    σ = approx_σ(pnc, lgc, ead, approx_σ_A, approx_σ_B, approx_σ_C)\n",
    "    p = (1 - normcdf((l-μ)/σ)) * pdf(Zdist, Z)\n",
    "    return p\n",
    "end\n",
    "\n",
    "ns = 2500\n",
    "samples = zeros(S, 2*ns)\n",
    "initialv = [-2.2, 2.2]\n",
    "\n",
    "for i in 1:2\n",
    "    @time ss = slicesample(fill(initialv[i], 1), π, ns;\n",
    "        step_limit=30, width=2., burn=100, thin=2)\n",
    "    samples[:,ns*(i-1)+1:ns*i] = ss\n",
    "end\n",
    "\n",
    "\n",
    "PyPlot.plt[:hist](vec(samples), bins=20, density=true)\n",
    "\n",
    "xs = -10:0.3:10\n",
    "ys = [π([x]) for x in xs]\n",
    "PyPlot.plt[:plot](xs, ys, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zero variance function\n",
    "\n",
    "Should not be symmetric, and they are not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 2500\n",
    "c = 4\n",
    "s = 1\n",
    "\n",
    "for l in [2]\n",
    "    param = Parameter(n,c,s,l)\n",
    "    let (N, C, S, ll, cmm, ead, lgc, cn, β, H, denom, weights) = unpack(param)\n",
    "        xs = -10:0.1:10\n",
    "        ys = [π([x]) for x in xs]\n",
    "        PyPlot.plt[:plot](xs, ys, color=\"red\", linestyle=\"--\")\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S=2\n",
    "\n",
    "slice sampler is doing OK, with initial point = 0,\n",
    "Since although it is multimodal in a slice aligned with an axis, the slice is able to correctly do sampling\n",
    "But still need to verify that the real distribution is about the same as one sampled. Suspect that it maybe multimodal as well\n",
    "- need to construct a meshgrid of `xs`, `ys`\n",
    "- compute `zs = pi([x,y] for x in xs, y in ys]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 2500\n",
    "c = 4\n",
    "s = 2\n",
    "l = 1.8\n",
    "param = Parameter(n,c,s,l)\n",
    "(N, C, S, l, cmm, ead, lgc, cn, β, H, denom, weights) = unpack(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z = zeros(S)\n",
    "βZ = zeros(N)\n",
    "phi0 = zeros(N, C+1)\n",
    "phi  = @view phi0[:,2:end]\n",
    "pnc = zeros(N, C)\n",
    "approx_μ_A = similar(weights)\n",
    "approx_σ_A = zeros(N, convert(Int, (C-1)*C/2))\n",
    "approx_σ_B = zeros(N)\n",
    "approx_σ_C = zeros(N)\n",
    "Zdist = MvNormal(S, 1)\n",
    "\n",
    "function π(Z)\n",
    "    mul!(βZ, β, Z)\n",
    "    @. phi = normcdf((H - βZ) / denom)\n",
    "    diff!(pnc, phi0; dims=2)\n",
    "    μ = approx_μ(pnc, weights, approx_μ_A)\n",
    "    σ = approx_σ(pnc, lgc, ead, approx_σ_A, approx_σ_B, approx_σ_C)\n",
    "    p = (1 - normcdf((l-μ)/σ)) * pdf(Zdist, Z)\n",
    "    return p\n",
    "end\n",
    "\n",
    "n_samples = 2000\n",
    "burn_ratio = 0.1\n",
    "initial_point = zeros(S)\n",
    "\n",
    "samples = slicesample(initial_point, π, n_samples;\n",
    "    step_limit=20,\n",
    "    width=0.5,\n",
    "    burn=Int(burn_ratio * n_samples),\n",
    "    thin=3)\n",
    "\n",
    "PyPlot.plt[:hist2d](samples[1,:], samples[2,:], bins=20)\n",
    "print(\"l=$l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.7.0",
   "language": "julia",
   "name": "julia-0.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
